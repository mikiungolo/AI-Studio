# ğŸ“‹ Guida alla Configurazione - AI-Studio

## Panoramica

AI-Studio utilizza un **file di configurazione centralizzato** (`config.yaml`) per gestire tutti i parametri del sistema. Questo approccio segue le **best practices** dell'ingegneria del software moderna.

## ğŸ¯ PerchÃ© un File di Configurazione?

### Vantaggi:

1. **Separazione Codice/Configurazione**: Modifichi i parametri senza toccare il codice Python
2. **Gestione Centralizzata**: Un parametro usato in piÃ¹ punti si cambia una sola volta
3. **AccessibilitÃ **: Chiunque puÃ² modificare i parametri senza conoscere Python
4. **Versionamento**: Puoi tenere diverse configurazioni per scenari diversi
5. **Sicurezza**: Le API key possono essere gestite tramite variabili d'ambiente

## ğŸ“‚ Struttura del Sistema

```
AI-Studio/
â”œâ”€â”€ config.yaml               # â† File di configurazione principale
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config_loader.py      # Modulo che carica config.yaml
â”‚   â”œâ”€â”€ llm_gen_engine.py     # Usa config per i parametri LLM
â”‚   â”œâ”€â”€ audio_processing.py   # Usa config per Whisper e FFmpeg
â”‚   â”œâ”€â”€ vision_processing.py  # Usa config per Computer Vision
â”‚   â””â”€â”€ interactive_agent.py  # Usa config per Editor e Tutor
â””â”€â”€ requirements.txt          # Include PyYAML
```

## ğŸ”§ Come Funziona

### 1. File di Configurazione (YAML)

Il formato **YAML** Ã¨ stato scelto perchÃ©:
- Ãˆ **leggibile** come testo normale
- Supporta **commenti** per documentare ogni parametro
- Ãˆ lo **standard** per configurazioni (Kubernetes, Docker, GitHub Actions, ecc.)
- Supporta **strutture gerarchiche** intuitive

Esempio da `config.yaml`:
```yaml
llm:
  model_name: "gemini-2.0-flash-exp"
  writer:
    temperature: 0.5      # Precisione logica per gli appunti
    top_p: 0.8
    max_output_tokens: 45000
  editor:
    temperature: 0.3      # SeveritÃ  massima per modifiche precise
```

### 2. Config Loader (Pattern Singleton)

Il file `config_loader.py` implementa il **Singleton Pattern**:
- Carica il YAML **una sola volta** all'avvio
- Ãˆ accessibile da **tutti i moduli** come oggetto globale
- Fornisce **proprietÃ  type-safe** (autocompletamento IDE)
- Supporta **variabili d'ambiente** per API keys

```python
from config_loader import config

# Accesso diretto alle proprietÃ 
temperature = config.writer_temperature  # 0.5
model = config.model_name                # "gemini-2.0-flash-exp"
```

### 3. Variabili d'Ambiente (Sicurezza)

Per le **API keys** sensibili, usa variabili d'ambiente:

```yaml
llm:
  api_key: "${GOOGLE_API_KEY}"  # Viene sostituita automaticamente
```

Nel tuo ambiente:
```bash
# Linux/Mac
export GOOGLE_API_KEY="your-secret-key-here"

# Windows PowerShell
$env:GOOGLE_API_KEY = "your-secret-key-here"
```

## âš™ï¸ Parametri Configurabili

### ğŸ¤– LLM (Large Language Model)

| Parametro | Descrizione | Default |
|-----------|-------------|---------|
| `model_name` | Modello Gemini da usare | `gemini-2.0-flash-exp` |
| `rpm` | Richieste al minuto (rate limit) | `5` |
| `writer.temperature` | CreativitÃ  nella generazione appunti | `0.5` |
| `writer.chunk_duration_sec` | Durata chunk in secondi (15min) | `900` |
| `editor.temperature` | Precisione nelle modifiche | `0.3` |
| `tutor.temperature` | NaturalitÃ  nelle risposte | `0.75` |

### ğŸ¤ Audio Processing

| Parametro | Descrizione | Default |
|-----------|-------------|---------|
| `whisper_model_size` | Modello Whisper (`tiny`, `base`, `small`, `medium`, `large-v3`) | `large-v3` |
| `device` | Hardware (`cpu`, `cuda`) | `cuda` |
| `vad_enabled` | Voice Activity Detection attivo | `true` |
| `audio_sample_rate` | Frequenza campionamento (Hz) | `16000` |

### ğŸ‘ï¸ Vision Processing

| Parametro | Descrizione | Default |
|-----------|-------------|---------|
| `change_threshold` | % schermo che deve cambiare (0.0-1.0) | `0.03` (3%) |
| `blur_kernel_size` | Dimensione kernel GaussianBlur | `21` |
| `pixel_threshold` | Soglia cambiamento pixel (0-255) | `25` |

## ğŸš€ Come Usare

### Scenario 1: Cambiare Modello LLM

Invece di modificare 3+ file Python, editi **una riga** in `config.yaml`:

```yaml
llm:
  model_name: "gemini-2.0-flash-exp"  # Cambia qui
```

### Scenario 2: Ottimizzare per GPU Meno Potente

```yaml
audio:
  whisper_model_size: "medium"  # Invece di large-v3
  compute_type: "int8"          # Invece di float16
```

### Scenario 3: Aumentare RPM (Account Pro)

```yaml
llm:
  rpm: 15  # Account Pro Gemini supporta 15 RPM
```

